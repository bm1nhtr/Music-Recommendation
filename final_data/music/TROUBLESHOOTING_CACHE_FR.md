# R√©solution du Probl√®me de Cache - Nodes Incorrects

## üî¥ Probl√®me

Lorsque vous relancez le preprocessing avec des param√®tres diff√©rents (ex: `--max_users 30 --max_artists 30`), les statistiques peuvent afficher un nombre incorrect de nodes (ex: 80 au lieu de 60).

**Sympt√¥mes** :
- Metadata indique `n_entities=60` (correct)
- Mais les statistiques affichent `Nombre de n≈ìuds: 80` (incorrect)
- Le fichier `kg_final.txt` contient bien 60 nodes, mais le loader lit 80

## üîç Cause

Le probl√®me vient du **fichier cache** `kg_final.npy` qui contient les donn√©es de l'ancien preprocessing. Le code dans `graph_loader.py` charge d'abord le fichier `.npy` s'il existe, au lieu de relire le fichier `.txt` mis √† jour.

```python
# Dans graph_loader.py ligne 69-70
if os.path.exists(kg_file + '.npy'):
    kg_np = np.load(kg_file + '.npy')  # ‚Üê Lit l'ancien cache
```

## ‚úÖ Solution Rapide

### ‚ö° Solution Automatique (Recommand√©e)

**Le syst√®me d√©tecte et corrige automatiquement les probl√®mes de cache !**

Lorsque vous lancez `python main.py`, le syst√®me :
1. V√©rifie si `kg_final.txt` a √©t√© modifi√© apr√®s le cache `.npy` (comparaison de timestamp)
2. V√©rifie si le nombre d'entit√©s dans le cache correspond aux m√©tadonn√©es
3. **Supprime automatiquement le cache obsol√®te** si n√©cessaire
4. R√©g√©n√®re le cache depuis le fichier `.txt` mis √† jour

**Vous n'avez plus besoin de supprimer manuellement le cache !** üéâ

### Option Manuelle (Si n√©cessaire)

Si vous voulez forcer la r√©g√©n√©ration du cache manuellement :

```bash
# Windows PowerShell
Remove-Item final_data\music\kg_final.npy
Remove-Item final_data\music\ratings_final.npy

# Linux/Mac
rm final_data/music/kg_final.npy
rm final_data/music/ratings_final.npy
```

Puis relancer votre script. Le fichier `.npy` sera r√©g√©n√©r√© automatiquement avec les bonnes donn√©es.

## üõ°Ô∏è Pr√©vention

### ‚úÖ M√©thode Automatique (Recommand√©e - D√©j√† Impl√©ment√©e)

Le syst√®me g√®re automatiquement la coh√©rence du cache :

1. **D√©tection automatique** : Le syst√®me v√©rifie la coh√©rence √† chaque chargement
2. **Correction automatique** : Le cache obsol√®te est supprim√© et r√©g√©n√©r√© automatiquement
3. **Aucune action requise** : Vous pouvez simplement lancer vos scripts normalement

**Workflow recommand√©** :
```bash
# 1. Relancer le preprocessing (si vous changez les param√®tres)
cd src
python preprocess.py --dataset music --reduce --max_users 30 --max_artists 30

# 2. Utiliser les donn√©es (le cache sera automatiquement g√©r√©)
python main.py --dataset music --visualize
```

### M√©thode Manuelle (Si vous voulez forcer la r√©g√©n√©ration)

Si vous voulez forcer la suppression du cache avant le preprocessing :

```bash
# 1. Supprimer le cache
Remove-Item final_data\music\kg_final.npy
Remove-Item final_data\music\ratings_final.npy

# 2. Relancer le preprocessing
cd src
python preprocess.py --dataset music --reduce --max_users 30 --max_artists 30
```

### V√©rification de Coh√©rence (Optionnel)

Pour v√©rifier manuellement la coh√©rence (le syst√®me le fait d√©j√† automatiquement) :

```python
from src.graph_loader import load_kg

n_entity, n_relation, kg, metadata = load_kg('final_data', 'music')

expected = metadata.get('n_artists_actual', 0) + metadata.get('n_users_actual', 0)
if n_entity != expected:
    print(f"‚ö†Ô∏è Incoh√©rence d√©tect√©e: n_entity={n_entity}, attendu={expected}")
    print("üí° Le syst√®me devrait avoir corrig√© cela automatiquement")
```

## üìù Note Technique

Le fichier `.npy` est cr√©√© pour **acc√©l√©rer le chargement** (plus rapide que lire un fichier texte). 

**Gestion automatique** : Le syst√®me d√©tecte maintenant automatiquement quand `kg_final.txt` change (via comparaison de timestamp) et r√©g√©n√®re le cache si n√©cessaire. Vous n'avez plus besoin de supprimer manuellement le cache.

**Comment √ßa marche** :
1. Le syst√®me compare le timestamp de `kg_final.txt` avec celui de `kg_final.npy`
2. Si `.txt` est plus r√©cent ‚Üí cache supprim√© et r√©g√©n√©r√©
3. Si les m√©tadonn√©es ne correspondent pas ‚Üí cache supprim√© et r√©g√©n√©r√©
4. Sinon ‚Üí cache r√©utilis√© (reproducibility garantie)

---

## ‚úÖ Solution Automatique (Impl√©ment√©e)

Le syst√®me d√©tecte maintenant automatiquement les incoh√©rences et r√©g√©n√®re le cache :

1. **V√©rification de timestamp** : Si `kg_final.txt` a √©t√© modifi√© apr√®s le cache `.npy`, le cache est automatiquement supprim√©
2. **V√©rification de metadata** : Si le nombre d'entit√©s dans le cache ne correspond pas aux m√©tadonn√©es, le cache est r√©g√©n√©r√©
3. **Reproducibility** : Si les fichiers n'ont pas chang√©, le cache est r√©utilis√© pour garantir la coh√©rence

Vous n'avez plus besoin de supprimer manuellement le cache - le syst√®me le fait automatiquement !

---

## üîê V√©rification d'Int√©grit√© et Reproducibility

### Probl√®me : Comment garantir que deux personnes avec les m√™mes param√®tres ont les m√™mes donn√©es ?

Lorsque vous travaillez en √©quipe, il est important de garantir que tous les membres obtiennent exactement les m√™mes donn√©es apr√®s le preprocessing, m√™me sur des machines diff√©rentes.

### Solution : Checksums (Hashes SHA256)

Le syst√®me calcule automatiquement des **checksums SHA256** pour les fichiers `kg_final.txt` et `ratings_final.txt` lors du preprocessing. Ces checksums sont sauvegard√©s dans `dataset_metadata.txt`.

#### Comment √ßa fonctionne

1. **Lors du preprocessing** :
   ```bash
   python preprocess.py --dataset music --reduce --max_users 30 --max_artists 50
   ```
   - Le syst√®me calcule automatiquement les hash SHA256 de `kg_final.txt` et `ratings_final.txt`
   - Les hash sont sauvegard√©s dans `dataset_metadata.txt` :
     ```
     kg_file_hash=abc123def456...
     ratings_file_hash=789xyz012...
     ```

2. **Lors du chargement** :
   ```bash
   python main.py --dataset music
   ```
   - Le syst√®me compare automatiquement les hash des fichiers actuels avec ceux dans metadata
   - Si les hash correspondent ‚Üí ‚úÖ Reproducibility garantie
   - Si les hash ne correspondent pas ‚Üí ‚ùå Les fichiers ont √©t√© modifi√©s ou corrompus

3. **V√©rification manuelle** :
   ```bash
   python main.py --dataset music --verify
   ```
   - V√©rifie uniquement l'int√©grit√© sans charger les donn√©es
   - Affiche un rapport d√©taill√© de v√©rification

#### Exemple de sortie

**Cas 1 : Donn√©es valides (reproducibility garantie)**
```
‚úÖ [VERIFICATION] Fichier KG valide (hash: abc123def4567890...)
‚úÖ [VERIFICATION] Fichier Ratings valide (hash: 789xyz0123456789...)
‚úÖ [VERIFICATION] Tous les fichiers sont valides - Reproducibility garantie!
```

**Cas 2 : Donn√©es invalides**
```
‚ùå [VERIFICATION] Fichier KG INVALIDE!
   Hash actuel:   abc123def4567890...
   Hash attendu:  xyz789abc0123456...
   ‚Üí Les donn√©es ne correspondent pas aux m√©tadonn√©es
‚ùå [VERIFICATION] Certains fichiers sont invalides - Reproducibility NON garantie!
```

### Workflow pour Travail en √âquipe

#### Sur la machine du premier d√©veloppeur :

1. **Pr√©processer les donn√©es** :
   ```bash
   cd src
   python preprocess.py --dataset music --reduce --max_users 30 --max_artists 50
   ```

2. **V√©rifier que tout est correct** :
   ```bash
   python main.py --dataset music --verify
   ```

3. **Commit dans git** :
   ```bash
   git add final_data/music/kg_final.txt
   git add final_data/music/ratings_final.txt
   git add final_data/music/dataset_metadata.txt
   git commit -m "Add preprocessed data with checksums"
   git push
   ```
   
   ‚ö†Ô∏è **Important** : Ne commitez PAS les fichiers `.npy` (ils sont d√©j√† dans `.gitignore`)

#### Sur la machine du deuxi√®me d√©veloppeur :

1. **R√©cup√©rer les fichiers** :
   ```bash
   git pull
   ```

2. **V√©rifier l'int√©grit√©** :
   ```bash
   cd src
   python main.py --dataset music --verify
   ```

3. **Si la v√©rification r√©ussit** :
   - ‚úÖ Les donn√©es sont identiques
   - ‚úÖ Reproducibility garantie
   - Vous pouvez utiliser les donn√©es en toute confiance

4. **Si la v√©rification √©choue** :
   - ‚ùå Les fichiers ont √©t√© modifi√©s ou corrompus
   - **Solution** : Relancez le preprocessing avec les m√™mes param√®tres :
     ```bash
     python preprocess.py --dataset music --reduce --max_users 30 --max_artists 50
     ```

### Avantages

1. **D√©tection automatique** : Le syst√®me d√©tecte automatiquement si les fichiers ont √©t√© modifi√©s
2. **Reproducibility garantie** : M√™me hash = m√™me donn√©es, m√™me sur des machines diff√©rentes
3. **Pas de comparaison manuelle** : Plus besoin de comparer les fichiers ligne par ligne
4. **S√©curit√©** : D√©tecte les corruptions de fichiers ou modifications accidentelles

### Notes Techniques

- **Algorithme de hash** : SHA256 (cryptographiquement s√ªr)
- **Performance** : Le calcul du hash est rapide m√™me pour les gros fichiers (lecture par chunks de 4KB)
- **Compatibilit√©** : Les anciens datasets sans checksums affichent un avertissement mais fonctionnent toujours
- **Cache** : Les fichiers `.npy` ne sont pas v√©rifi√©s (ils sont r√©g√©n√©r√©s automatiquement depuis `.txt`)

---

**Derni√®re mise √† jour** : Ajout du syst√®me de checksums pour garantir la reproducibility entre diff√©rentes machines

